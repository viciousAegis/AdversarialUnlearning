{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # pytorch backend\n",
    "from grb.dataset import Dataset\n",
    "from grb.model.torch import GCN\n",
    "from grb.trainer import Trainer\n",
    "from grb.attack.injection.tdgia import TDGIA\n",
    "from grb.utils.normalize import GCNAdjNorm\n",
    "# from grb.defense import AdvTrainer\n",
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# import cora\n",
    "dataset_name = 'Cora'\n",
    "\n",
    "# Load the dataset\n",
    "dataset = Planetoid(root='data', name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grb.dataset import CustomDataset\n",
    "from torch_geometric.utils import to_scipy_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom dataset from planetoid dataset\n",
    "\n",
    "adj_matrix = to_scipy_sparse_matrix(dataset[0].edge_index)\n",
    "features = dataset[0].x\n",
    "labels = dataset[0].y\n",
    "name = 'cora-custom'\n",
    "data_dir = 'grb_data/cora'\n",
    "save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRB data splitting...\n",
      "    Average degree of all nodes: 3.8981\n",
      "    Average degree of 5% nodes with small degree: 1.0000\n",
      "    Average degree of 5% nodes with large degree: 17.4265\n",
      "    Average degree of 30% nodes (easy): 1.5690\n",
      "    Randomly sampled 270 nodes\n",
      "    Average degree of 30% nodes (medium): 3.0221\n",
      "    Randomly sampled 270 nodes\n",
      "    Average degree of 30% nodes (hard): 5.3202\n",
      "    Randomly sampled 270 nodes\n",
      "    Number of training/validation nodes: 1624/274\n",
      "    No duplicate.\n",
      "    Saved in grb_data/cora.\n",
      "Custom Dataset 'cora-custom' loaded.\n",
      "    Number of nodes: 2708\n",
      "    Number of edges: 5278\n",
      "    Number of features: 1433\n",
      "    Number of classes: 7\n",
      "    Number of train samples: 1624\n",
      "    Number of val samples: 274\n",
      "    Number of test samples: 810\n",
      "    Dataset mode: full\n",
      "    Feature range [0.0000, 1.0000]\n"
     ]
    }
   ],
   "source": [
    "cora_custom = CustomDataset(\n",
    "    adj=adj_matrix,\n",
    "    features=features,\n",
    "    labels=labels,\n",
    "    name=name,\n",
    "    data_dir=data_dir,\n",
    "    save=save,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 10556 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_custom.adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "source_dir = 'grb_data/cora'\n",
    "destination_dir = 'data/grb-cora'\n",
    "\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "for file_name in os.listdir(source_dir):\n",
    "    shutil.copy(os.path.join(source_dir, file_name), destination_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'grb-cora' loaded.\n",
      "    Number of nodes: 2708\n",
      "    Number of edges: 5278\n",
      "    Number of features: 1433\n",
      "    Number of classes: 7\n",
      "    Number of train samples: 1624\n",
      "    Number of val samples: 274\n",
      "    Number of test samples: 270\n",
      "    Dataset mode: hard\n",
      "    Feature range: [-0.0718, 0.9282]\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(name='grb-cora', data_dir='data/grb-cora', mode='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grb.model.torch import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(in_features=dataset.num_features,\n",
    "            out_features=dataset.num_classes,\n",
    "            hidden_features=[64, 64], n_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 00013 | Train loss 0.3302 | Train score 0.9329 | Val loss 1.2986 | Val score 0.8504:   6%|▌         | 12/200 [00:00<00:03, 55.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00001 | Best validation score: 0.7883\n",
      "Model saved in './tmp_2024_05_15_15_23_54/model.pt'.\n",
      "Epoch 00005 | Best validation score: 0.8029\n",
      "Model saved in './tmp_2024_05_15_15_23_54/model.pt'.\n",
      "Epoch 00007 | Best validation score: 0.8175\n",
      "Model saved in './tmp_2024_05_15_15_23_54/model.pt'.\n",
      "Epoch 00008 | Best validation score: 0.8248\n",
      "Model saved in './tmp_2024_05_15_15_23_54/model.pt'.\n",
      "Epoch 00009 | Best validation score: 0.8321\n",
      "Model saved in './tmp_2024_05_15_15_23_54/model.pt'.\n",
      "Epoch 00011 | Best validation score: 0.8358\n",
      "Model saved in './tmp_2024_05_15_15_23_54/model.pt'.\n",
      "Epoch 00012 | Best validation score: 0.8394\n",
      "Model saved in './tmp_2024_05_15_15_23_54/model.pt'.\n",
      "Epoch 00013 | Best validation score: 0.8504\n",
      "Model saved in './tmp_2024_05_15_15_23_54/model.pt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 00025 | Train loss 0.1729 | Train score 0.9501 | Val loss 1.2117 | Val score 0.8577:  12%|█▎        | 25/200 [00:00<00:02, 58.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00014 | Best validation score: 0.8540\n",
      "Model saved in './tmp_2024_05_15_15_23_54/model.pt'.\n",
      "Epoch 00015 | Best validation score: 0.8686\n",
      "Model saved in './tmp_2024_05_15_15_23_54/model.pt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 00199 | Train loss 0.0562 | Train score 0.9858 | Val loss 1.7454 | Val score 0.8431: 100%|██████████| 200/200 [00:03<00:00, 61.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in './tmp_2024_05_15_15_23_54/final_model.pt'.\n",
      "Training finished. Best validation score: 0.8686\n",
      "Training runtime: 3.2577.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "adam = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "trainer = Trainer(dataset=dataset, optimizer=adam, loss=torch.nn.functional.nll_loss)\n",
    "trainer.train(model=model, n_epoch=200, train_mode=\"inductive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacking: Sequential inject 4/20 nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 15.6292, Surrogate test score: 0.9778: 100%|██████████| 10/10 [00:00<00:00, 37.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacking: Sequential inject 8/20 nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 15.3678, Surrogate test score: 0.9593: 100%|██████████| 10/10 [00:00<00:00, 48.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacking: Sequential inject 12/20 nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 15.1927, Surrogate test score: 0.9444: 100%|██████████| 10/10 [00:00<00:00, 34.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacking: Sequential inject 16/20 nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 14.5031, Surrogate test score: 0.9037: 100%|██████████| 10/10 [00:00<00:00, 35.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacking: Sequential inject 20/20 nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 13.9904, Surrogate test score: 0.8667: 100%|██████████| 10/10 [00:00<00:00, 38.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack runtime: 1.5817.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from grb.attack.injection.tdgia import TDGIA\n",
    "\n",
    "# Attack configuration\n",
    "tdgia = TDGIA(\n",
    "    lr=0.01,\n",
    "    n_epoch=10,\n",
    "    n_inject_max=20,\n",
    "    n_edge_max=20,\n",
    "    feat_lim_min=-0.9,\n",
    "    feat_lim_max=0.9,\n",
    "    sequential_step=0.2,\n",
    ")\n",
    "\n",
    "# covert adj to coo format\n",
    "adj = dataset.adj.tocoo()\n",
    "\n",
    "# Apply attack\n",
    "rst = tdgia.attack(\n",
    "    model=model,\n",
    "    adj=adj,\n",
    "    features=dataset.features,\n",
    "    target_mask=dataset.test_mask,\n",
    "    adj_norm_func=GCNAdjNorm,\n",
    ")\n",
    "# Get modified adj and features\n",
    "adj_attack, features_attack = rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "addmm: Argument #3 (dense): Expected dim 0 size 2728, got 20",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgrb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[0;32m----> 3\u001b[0m test_score \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43madj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madj_attack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures_attack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43madj_norm_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGCNAdjNorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m test_score\n",
      "File \u001b[0;32m~/Desktop/Research/unlearning/AdversarialUnlearning/grb/utils/utils.py:287\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, features, adj, labels, feat_norm, adj_norm_func, eval_metric, mask, device)\u001b[0m\n\u001b[1;32m    283\u001b[0m features \u001b[38;5;241m=\u001b[39m feat_preprocess(features,\n\u001b[1;32m    284\u001b[0m                            feat_norm\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfeat_norm \u001b[38;5;28;01mif\u001b[39;00m feat_norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m feat_norm,\n\u001b[1;32m    285\u001b[0m                            device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    286\u001b[0m labels \u001b[38;5;241m=\u001b[39m label_preprocess(labels\u001b[38;5;241m=\u001b[39mlabels, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m--> 287\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     logits \u001b[38;5;241m=\u001b[39m logits[:labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[0;32m~/Desktop/Research/.env/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Research/.env/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Research/unlearning/AdversarialUnlearning/grb/model/torch/gcn.py:109\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m    107\u001b[0m         x \u001b[38;5;241m=\u001b[39m layer(x)\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Desktop/Research/.env/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Research/.env/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Research/unlearning/AdversarialUnlearning/grb/model/torch/gcn.py:300\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m \n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    299\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(x)\n\u001b[0;32m--> 300\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: addmm: Argument #3 (dense): Expected dim 0 size 2728, got 20"
     ]
    }
   ],
   "source": [
    "from grb.utils import evaluate\n",
    "\n",
    "test_score = evaluate(\n",
    "    model=model,\n",
    "    adj=adj_attack,\n",
    "    features=features_attack,\n",
    "    labels=dataset.labels,\n",
    "    mask=dataset.test_mask,\n",
    "    adj_norm_func=GCNAdjNorm,\n",
    ")\n",
    "\n",
    "test_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
