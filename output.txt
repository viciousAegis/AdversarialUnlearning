==========================================
SLURM_JOB_ID = 1147437
SLURM_NODELIST = gnode037
SLURM_JOB_GPUS = 0
==========================================
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_153556-olyi3up3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-cloud-30
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/olyi3up3
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1544ab406a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.385 MB of 0.391 MB uploaded (0.002 MB deduped)wandb: | 0.385 MB of 0.395 MB uploaded (0.002 MB deduped)wandb: / 0.395 MB of 0.395 MB uploaded (0.002 MB deduped)wandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run fiery-cloud-30 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/olyi3up3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_153556-olyi3up3/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_153714-i5a4rl82
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-firefly-31
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/i5a4rl82
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x151e2e6d9ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.388 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run rare-firefly-31 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/i5a4rl82
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_153714-i5a4rl82/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_153824-6v647z7h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-spaceship-32
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/6v647z7h
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1464b7088ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run still-spaceship-32 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/6v647z7h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_153824-6v647z7h/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_153938-enqh5dqz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-dawn-33
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/enqh5dqz
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1468f6d69ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.385 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run desert-dawn-33 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/enqh5dqz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_153938-enqh5dqz/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_154053-x9s5bawa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-resonance-34
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/x9s5bawa
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14863f001ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run zesty-resonance-34 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/x9s5bawa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_154053-x9s5bawa/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_154209-45kxdv3m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-waterfall-35
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/45kxdv3m
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148561986ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run eternal-waterfall-35 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/45kxdv3m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_154209-45kxdv3m/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_154318-hvxdzvdm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-meadow-37
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hvxdzvdm
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x150ccfd92ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run olive-meadow-37 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hvxdzvdm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_154318-hvxdzvdm/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_154433-efkcsxlu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-dew-40
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/efkcsxlu
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14c25a23dd00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.379 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run pretty-dew-40 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/efkcsxlu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_154433-efkcsxlu/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_154551-e6a0m3n9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-energy-44
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/e6a0m3n9
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149799795ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.387 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run smart-energy-44 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/e6a0m3n9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_154551-e6a0m3n9/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_154659-5fx2vpat
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-snowflake-47
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/5fx2vpat
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1471c8d2ba90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.385 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run curious-snowflake-47 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/5fx2vpat
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_154659-5fx2vpat/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_154818-cehwdeby
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-star-51
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/cehwdeby
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14756c37fac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run upbeat-star-51 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/cehwdeby
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_154818-cehwdeby/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_154932-v528tgv0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-serenity-55
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/v528tgv0
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1465d5289ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run serene-serenity-55 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/v528tgv0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_154932-v528tgv0/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_155040-7ns8jxq1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-water-58
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7ns8jxq1
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1521105e1a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run cerulean-water-58 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7ns8jxq1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_155040-7ns8jxq1/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_155153-4pkf6cup
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-planet-61
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4pkf6cup
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14a1cf774a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.381 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run smart-planet-61 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4pkf6cup
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_155153-4pkf6cup/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_155307-dks3ppa7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-donkey-64
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/dks3ppa7
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x152a08312a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run zesty-donkey-64 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/dks3ppa7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_155307-dks3ppa7/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_155423-kykxczwc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-river-67
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/kykxczwc
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14ba8e0b3ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run vibrant-river-67 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/kykxczwc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_155423-kykxczwc/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_155538-nuzqhha9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sunset-69
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nuzqhha9
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14d894d86ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run genial-sunset-69 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nuzqhha9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_155538-nuzqhha9/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_155649-o30st95y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-wave-73
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/o30st95y
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148f2c30cac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run icy-wave-73 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/o30st95y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_155649-o30st95y/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_155756-slox9t9v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-darkness-76
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/slox9t9v
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14b5d5b6cac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run wobbly-darkness-76 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/slox9t9v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_155756-slox9t9v/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_155911-aw977vl8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-star-80
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/aw977vl8
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x150c5af94ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run azure-star-80 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/aw977vl8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_155911-aw977vl8/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_160027-i8sldror
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-cosmos-84
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/i8sldror
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x150d08733a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.383 MB uploadedwandb: \ 0.383 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run eternal-cosmos-84 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/i8sldror
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_160027-i8sldror/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_160135-8t6b1skt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-frost-87
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/8t6b1skt
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14e5aebbea90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run icy-frost-87 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/8t6b1skt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_160135-8t6b1skt/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_160250-8m0xeko9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-pond-90
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/8m0xeko9
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14cf821ada90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run fancy-pond-90 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/8m0xeko9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_160250-8m0xeko9/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_160402-ercafuzp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-armadillo-92
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ercafuzp
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1481c22dfa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run sweet-armadillo-92 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ercafuzp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_160402-ercafuzp/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_160518-rotllak3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-dream-96
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/rotllak3
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15299001ea60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run scarlet-dream-96 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/rotllak3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_160518-rotllak3/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_160635-0fpta2ap
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-bird-99
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/0fpta2ap
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149143b12a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run eager-bird-99 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/0fpta2ap
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_160635-0fpta2ap/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_160750-7le5ng1o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-surf-102
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7le5ng1o
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x154777457ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run ethereal-surf-102 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7le5ng1o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_160750-7le5ng1o/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_160907-3s2ir2fl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-salad-105
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/3s2ir2fl
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149edc0faa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run hearty-salad-105 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/3s2ir2fl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_160907-3s2ir2fl/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_161022-wopcyne2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-plant-108
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wopcyne2
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1465585d7a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.383 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run lunar-plant-108 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wopcyne2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_161022-wopcyne2/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_161138-09hq0dkv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-shadow-111
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/09hq0dkv
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15243a01aa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run deep-shadow-111 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/09hq0dkv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_161138-09hq0dkv/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_161252-jrxu6aum
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-leaf-114
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/jrxu6aum
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14f338628d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.381 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run elated-leaf-114 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/jrxu6aum
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_161252-jrxu6aum/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_161411-c844nzfn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-universe-117
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/c844nzfn
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1545c3e27a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run treasured-universe-117 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/c844nzfn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_161411-c844nzfn/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_161525-hjvxglwu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-pyramid-120
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hjvxglwu
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x154e18dcaa30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run olive-pyramid-120 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hjvxglwu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_161525-hjvxglwu/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_161641-w43t15oj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-terrain-123
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/w43t15oj
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x151d91830d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.381 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run upbeat-terrain-123 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/w43t15oj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_161641-w43t15oj/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_161757-6b0es3qu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-valley-127
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/6b0es3qu
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1512eb5cca90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.379 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run drawn-valley-127 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/6b0es3qu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_161757-6b0es3qu/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_161911-yd0ceglv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-totem-131
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/yd0ceglv
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x151c1a5fea90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run blooming-totem-131 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/yd0ceglv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_161911-yd0ceglv/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_162027-hhzuolf0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-snowflake-137
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hhzuolf0
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14dc5f799ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run dauntless-snowflake-137 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hhzuolf0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_162027-hhzuolf0/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_162134-tkokz3av
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-valley-142
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/tkokz3av
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14b285f62a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.388 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run azure-valley-142 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/tkokz3av
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_162134-tkokz3av/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_162249-q11s0mob
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-grass-147
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/q11s0mob
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14e917207ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run pleasant-grass-147 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/q11s0mob
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_162249-q11s0mob/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_162401-v55f0a6f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-music-152
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/v55f0a6f
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149178b81a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run fresh-music-152 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/v55f0a6f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_162401-v55f0a6f/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_162518-h527dqcy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-morning-158
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/h527dqcy
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149d09dcfac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run royal-morning-158 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/h527dqcy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_162518-h527dqcy/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_162635-1ytpwt1i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-bee-163
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/1ytpwt1i
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x151ba9a53ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run glorious-bee-163 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/1ytpwt1i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_162635-1ytpwt1i/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_162751-k0ahawv8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sun-168
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/k0ahawv8
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x151f42cd8a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run dutiful-sun-168 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/k0ahawv8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_162751-k0ahawv8/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_162906-30sknlmy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-galaxy-173
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/30sknlmy
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1551d4de8ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run cosmic-galaxy-173 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/30sknlmy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_162906-30sknlmy/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_163022-sjrdvl5y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-eon-178
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/sjrdvl5y
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14b53c698a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run neat-eon-178 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/sjrdvl5y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_163022-sjrdvl5y/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_163135-0hzi5rnr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-glade-183
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/0hzi5rnr
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1487ebff6a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run lively-glade-183 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/0hzi5rnr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_163135-0hzi5rnr/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_163246-o34d1a2n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-cosmos-188
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/o34d1a2n
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1514c9f90a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.383 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run expert-cosmos-188 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/o34d1a2n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_163246-o34d1a2n/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_163403-xy7u4yun
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-water-193
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/xy7u4yun
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1523f4513a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run graceful-water-193 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/xy7u4yun
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_163403-xy7u4yun/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_163519-ydk8daqb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-aardvark-198
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ydk8daqb
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14ac0a092a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run deft-aardvark-198 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ydk8daqb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_163519-ydk8daqb/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_163633-c0be1ajp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-bird-203
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/c0be1ajp
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14762fca3ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run sweet-bird-203 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/c0be1ajp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_163633-c0be1ajp/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_163748-vkfbmvem
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-glitter-208
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vkfbmvem
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14ce4b3fed00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run dry-glitter-208 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vkfbmvem
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_163748-vkfbmvem/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_163906-7lb8ojs0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-plant-211
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7lb8ojs0
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14de8cacaac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run glamorous-plant-211 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7lb8ojs0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_163906-7lb8ojs0/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_164022-vh9b3as0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-dragon-212
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vh9b3as0
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14e28774ca60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run restful-dragon-212 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vh9b3as0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_164022-vh9b3as0/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_164137-jue5yzfu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-cherry-213
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/jue5yzfu
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149177d7ca90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run eternal-cherry-213 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/jue5yzfu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_164137-jue5yzfu/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_164250-vadipcy0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-waterfall-214
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vadipcy0
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x150b6fe98ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run devout-waterfall-214 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vadipcy0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_164250-vadipcy0/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_164358-n29pag73
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-microwave-215
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/n29pag73
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14c3a588fa30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run efficient-microwave-215 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/n29pag73
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_164358-n29pag73/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_164515-mfcpgs81
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-snow-216
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/mfcpgs81
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14c6de213a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run comic-snow-216 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/mfcpgs81
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_164515-mfcpgs81/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_164626-ld4kcr6a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-moon-217
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ld4kcr6a
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x152c9b184ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run pious-moon-217 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ld4kcr6a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_164626-ld4kcr6a/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_164741-u0mx6y54
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-star-218
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/u0mx6y54
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14f004909d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run amber-star-218 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/u0mx6y54
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_164741-u0mx6y54/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_164858-ic0ygp9u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-firebrand-219
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ic0ygp9u
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148148c23ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run pious-firebrand-219 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ic0ygp9u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_164858-ic0ygp9u/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_165019-3o0ol34t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sea-220
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/3o0ol34t
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14ce050eaa60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run usual-sea-220 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/3o0ol34t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_165019-3o0ol34t/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_165137-ys5565ik
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-disco-221
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ys5565ik
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14dede732ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run young-disco-221 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ys5565ik
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_165137-ys5565ik/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_165253-u7zq7tq5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-lake-222
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/u7zq7tq5
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148165970ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.381 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run polar-lake-222 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/u7zq7tq5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_165253-u7zq7tq5/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_165403-guj5u7jt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-dew-223
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/guj5u7jt
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14c8920aba90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.387 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run feasible-dew-223 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/guj5u7jt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_165403-guj5u7jt/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_165519-iktcdl54
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-jazz-224
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/iktcdl54
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x152da65c9a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run glorious-jazz-224 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/iktcdl54
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_165519-iktcdl54/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_165638-4myagpri
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-voice-225
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4myagpri
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x152f36eb2a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run dashing-voice-225 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4myagpri
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_165638-4myagpri/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_165749-jshtuv21
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-pond-226
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/jshtuv21
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15259853ca90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.383 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run upbeat-pond-226 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/jshtuv21
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_165749-jshtuv21/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_165903-052wvuzh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-cherry-227
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/052wvuzh
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14f11d67ca60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run zany-cherry-227 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/052wvuzh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_165903-052wvuzh/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_170016-ifudajns
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-darkness-228
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ifudajns
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14fe142e5a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run sparkling-darkness-228 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ifudajns
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_170016-ifudajns/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_170134-ordl84du
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-valley-229
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ordl84du
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14bbeb9d8a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run drawn-valley-229 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ordl84du
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_170134-ordl84du/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_170252-3u29q7nq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-breeze-230
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/3u29q7nq
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14ff8f944a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run chocolate-breeze-230 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/3u29q7nq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_170252-3u29q7nq/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_170405-hx7fibp1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-pyramid-231
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hx7fibp1
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146e988eaa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run cerulean-pyramid-231 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hx7fibp1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_170405-hx7fibp1/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_170518-adkjiz3d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-cherry-232
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/adkjiz3d
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14ce77b80a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.383 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run happy-cherry-232 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/adkjiz3d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_170518-adkjiz3d/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_170638-fji3trub
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-night-233
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/fji3trub
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15141a8b6a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run colorful-night-233 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/fji3trub
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_170638-fji3trub/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_170750-pslsmc28
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-butterfly-234
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/pslsmc28
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14b942596a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.383 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.387 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run rosy-butterfly-234 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/pslsmc28
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_170750-pslsmc28/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_170905-6i0a5w9b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-deluge-235
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/6i0a5w9b
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148ec63a4a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run hardy-deluge-235 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/6i0a5w9b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_170905-6i0a5w9b/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_171019-5fczufj1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-dew-236
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/5fczufj1
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148269e33a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run helpful-dew-236 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/5fczufj1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_171019-5fczufj1/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_171134-smwhlub5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-snowflake-237
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/smwhlub5
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14f915698d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run volcanic-snowflake-237 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/smwhlub5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_171134-smwhlub5/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_171250-f7t9uv8k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-cosmos-238
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/f7t9uv8k
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146142561d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run azure-cosmos-238 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/f7t9uv8k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_171250-f7t9uv8k/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_171404-0kb0muer
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-wind-239
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/0kb0muer
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x145abdfaca90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run atomic-wind-239 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/0kb0muer
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_171404-0kb0muer/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_171523-kymkfvo2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-pyramid-240
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/kymkfvo2
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14a14c8dba30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run devout-pyramid-240 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/kymkfvo2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_171523-kymkfvo2/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_171639-7gov5gw1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-glade-241
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7gov5gw1
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1539daf4aa60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.387 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run easy-glade-241 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7gov5gw1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_171639-7gov5gw1/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_171756-ycdh9k4m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-serenity-242
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ycdh9k4m
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14ca27910a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run floral-serenity-242 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ycdh9k4m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_171756-ycdh9k4m/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_171912-an9uc571
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-snow-243
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/an9uc571
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x145d528fda60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run firm-snow-243 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/an9uc571
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_171912-an9uc571/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_172029-12bjm0zb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-breeze-244
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/12bjm0zb
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1550f6110a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run noble-breeze-244 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/12bjm0zb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_172029-12bjm0zb/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_172147-pi283ya2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-paper-245
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/pi283ya2
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14fecd949a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.385 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run zesty-paper-245 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/pi283ya2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_172147-pi283ya2/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_172305-usfcr6mp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-disco-246
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/usfcr6mp
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14a2d257fa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run dauntless-disco-246 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/usfcr6mp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_172305-usfcr6mp/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_172421-etv7phxg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-frog-247
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/etv7phxg
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1470feeeaa00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run peachy-frog-247 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/etv7phxg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_172421-etv7phxg/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_172540-d70l5yxu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-rain-248
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/d70l5yxu
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14e9bc15da90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run eternal-rain-248 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/d70l5yxu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_172540-d70l5yxu/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_172656-zm4r8xz2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-pyramid-249
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/zm4r8xz2
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x147cf7bada90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run faithful-pyramid-249 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/zm4r8xz2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_172656-zm4r8xz2/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_172817-hwxup8n3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-cherry-250
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hwxup8n3
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1526eb9e6a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run dry-cherry-250 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hwxup8n3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_172817-hwxup8n3/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_172935-hu2r0gqr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-star-251
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hu2r0gqr
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1516a6d1bd00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run clean-star-251 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hu2r0gqr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_172935-hu2r0gqr/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_173042-7dprmkrq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sponge-252
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7dprmkrq
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14680dc76a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.381 MB of 0.389 MB uploadedwandb: - 0.385 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run flowing-sponge-252 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7dprmkrq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_173042-7dprmkrq/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_173201-bh8shztg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-field-253
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/bh8shztg
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14a759fced00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run rich-field-253 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/bh8shztg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_173201-bh8shztg/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_173318-8z93xhjp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-capybara-254
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/8z93xhjp
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1484ec1d3d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run kind-capybara-254 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/8z93xhjp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_173318-8z93xhjp/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_173435-jsyfzz24
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-plant-255
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/jsyfzz24
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14782eeb8a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run divine-plant-255 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/jsyfzz24
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_173435-jsyfzz24/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_173552-awhg5drt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-durian-256
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/awhg5drt
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x155393552d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.383 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run worldly-durian-256 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/awhg5drt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_173552-awhg5drt/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_173709-7894s44x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-moon-257
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7894s44x
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148100010a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.387 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run magic-moon-257 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7894s44x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_173709-7894s44x/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_173828-ogpt31uj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-spaceship-258
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ogpt31uj
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x155036230a00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.387 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run skilled-spaceship-258 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ogpt31uj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_173828-ogpt31uj/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_173943-trqqjhob
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-breeze-259
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/trqqjhob
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1512e8bb8a00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.383 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run glad-breeze-259 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/trqqjhob
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_173943-trqqjhob/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_174053-dehkuy3k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sea-260
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/dehkuy3k
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1470336b8a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run lyric-sea-260 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/dehkuy3k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_174053-dehkuy3k/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_174209-tkzya4bp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-yogurt-261
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/tkzya4bp
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x152a26a94a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run resilient-yogurt-261 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/tkzya4bp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_174209-tkzya4bp/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_174326-mdbld6gt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-frost-262
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/mdbld6gt
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148fca140a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run stoic-frost-262 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/mdbld6gt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_174326-mdbld6gt/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_174443-qkvi3nax
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-silence-263
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/qkvi3nax
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14cd56521a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run silvery-silence-263 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/qkvi3nax
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_174443-qkvi3nax/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_174558-36n0m7tq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-pine-264
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/36n0m7tq
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1495ef183a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: | 0.385 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run ethereal-pine-264 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/36n0m7tq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_174558-36n0m7tq/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_174717-ubaftbud
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sponge-265
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ubaftbud
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x145e69006a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run ethereal-sponge-265 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ubaftbud
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_174717-ubaftbud/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_174835-tsm83fsy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-thunder-266
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/tsm83fsy
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x147c3d427a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.381 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run worldly-thunder-266 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/tsm83fsy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_174835-tsm83fsy/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_174945-m299sd9o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-darkness-267
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/m299sd9o
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1465ae08aa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run glamorous-darkness-267 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/m299sd9o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_174945-m299sd9o/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_175101-jlgga9p2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-gorge-268
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/jlgga9p2
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x152dc5b38a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.385 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run exalted-gorge-268 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/jlgga9p2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_175101-jlgga9p2/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_175220-q6xsjwae
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sponge-269
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/q6xsjwae
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x147d14eb5a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run quiet-sponge-269 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/q6xsjwae
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_175220-q6xsjwae/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_175337-bxx4u590
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-rain-270
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/bxx4u590
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x151d8c70da60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run drawn-rain-270 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/bxx4u590
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_175337-bxx4u590/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_175451-9czrsyd6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-resonance-271
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/9czrsyd6
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x155239e8cd00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.381 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run stellar-resonance-271 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/9czrsyd6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_175451-9czrsyd6/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_175607-r9ll464g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-bee-272
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/r9ll464g
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14f32b77ca90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.387 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run sweet-bee-272 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/r9ll464g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_175607-r9ll464g/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_175717-ehi3r9sh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-armadillo-273
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ehi3r9sh
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148c9bd56a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run rose-armadillo-273 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ehi3r9sh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_175717-ehi3r9sh/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_175834-q7ca78de
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-lake-274
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/q7ca78de
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14816579fa60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run astral-lake-274 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/q7ca78de
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_175834-q7ca78de/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_175949-iu6hse6t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-microwave-275
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/iu6hse6t
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x153dcff1da60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.383 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run whole-microwave-275 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/iu6hse6t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_175949-iu6hse6t/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_180105-ytajsfq5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-bee-276
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ytajsfq5
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14dec7dc7a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run fanciful-bee-276 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ytajsfq5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_180105-ytajsfq5/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_180222-6tbwgbrm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-waterfall-277
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/6tbwgbrm
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1534fecc3a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run bright-waterfall-277 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/6tbwgbrm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_180222-6tbwgbrm/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_180336-g4wfblut
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-spaceship-278
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/g4wfblut
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14fb0ce8ba90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run misunderstood-spaceship-278 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/g4wfblut
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_180336-g4wfblut/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_180453-r6rao489
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-tree-279
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/r6rao489
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146ded8cea60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.383 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run drawn-tree-279 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/r6rao489
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_180453-r6rao489/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_180609-umibrczb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-plant-280
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/umibrczb
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1546dee57d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run vibrant-plant-280 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/umibrczb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_180609-umibrczb/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_180728-dm2uzr4x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-aardvark-281
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/dm2uzr4x
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1531656a7a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run splendid-aardvark-281 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/dm2uzr4x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_180728-dm2uzr4x/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_180841-qbqaxbxo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-firefly-282
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/qbqaxbxo
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146a7f3d4a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.383 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run vibrant-firefly-282 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/qbqaxbxo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_180841-qbqaxbxo/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_180955-hhg91h8x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-eon-283
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hhg91h8x
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15213317ba60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run smooth-eon-283 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hhg91h8x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_180955-hhg91h8x/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_181108-q0v2chny
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-pond-284
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/q0v2chny
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14bbde3caa60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run prime-pond-284 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/q0v2chny
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_181108-q0v2chny/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_181221-6oc20j7o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-feather-285
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/6oc20j7o
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15342bc4da90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run leafy-feather-285 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/6oc20j7o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_181221-6oc20j7o/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_181339-s368cytm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-monkey-286
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/s368cytm
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1523b6cbfa60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run efficient-monkey-286 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/s368cytm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_181339-s368cytm/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_181455-nyxfy6as
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-plasma-287
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nyxfy6as
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1492e0beba30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.385 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run dutiful-plasma-287 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nyxfy6as
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_181455-nyxfy6as/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_181611-lvt1v3oe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-dust-288
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/lvt1v3oe
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14b984b0ca90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run clean-dust-288 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/lvt1v3oe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_181611-lvt1v3oe/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_181727-1lkdect6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-bush-289
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/1lkdect6
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149785544a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run trim-bush-289 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/1lkdect6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_181727-1lkdect6/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_181840-r8u1kj46
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-smoke-290
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/r8u1kj46
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14f800ad0a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run faithful-smoke-290 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/r8u1kj46
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_181840-r8u1kj46/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_181953-eyefvnqt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-frost-291
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/eyefvnqt
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14c974929a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run true-frost-291 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/eyefvnqt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_181953-eyefvnqt/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_182107-9sta71bf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-eon-292
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/9sta71bf
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14fb66507a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run likely-eon-292 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/9sta71bf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_182107-9sta71bf/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_182221-uwbhw2hd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-universe-293
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/uwbhw2hd
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14e26897ea60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.379 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run earnest-universe-293 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/uwbhw2hd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_182221-uwbhw2hd/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_182337-88u9j6oi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-bee-294
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/88u9j6oi
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148efa835a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run stellar-bee-294 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/88u9j6oi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_182337-88u9j6oi/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_182454-9rj3et81
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-wildflower-295
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/9rj3et81
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14775d394a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run usual-wildflower-295 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/9rj3et81
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_182454-9rj3et81/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_182611-t86hnmpe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-blaze-296
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/t86hnmpe
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x147904dc7a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run absurd-blaze-296 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/t86hnmpe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_182611-t86hnmpe/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_182725-9o5u5rf4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-disco-297
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/9o5u5rf4
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149e16b04a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run sleek-disco-297 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/9o5u5rf4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_182725-9o5u5rf4/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_182839-wqhq8u34
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-bush-298
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wqhq8u34
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x150889d7ba60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run glowing-bush-298 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wqhq8u34
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_182839-wqhq8u34/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_182954-2w4i02jd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-rain-299
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/2w4i02jd
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14772067da30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run legendary-rain-299 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/2w4i02jd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_182954-2w4i02jd/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_183108-viy1xe1f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-cloud-300
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/viy1xe1f
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149d1cb1ba30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run apricot-cloud-300 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/viy1xe1f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_183108-viy1xe1f/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_183223-hwmqm8xp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-monkey-301
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hwmqm8xp
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1522dc930a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run balmy-monkey-301 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hwmqm8xp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_183223-hwmqm8xp/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_183338-cjkj4sug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-spaceship-302
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/cjkj4sug
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146011b3ea90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run solar-spaceship-302 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/cjkj4sug
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_183338-cjkj4sug/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_183444-4zygqseb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-field-303
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4zygqseb
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146e8c95aa30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run dashing-field-303 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4zygqseb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_183444-4zygqseb/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_183602-11r1xptp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-wood-304
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/11r1xptp
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15341f9d0a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run exalted-wood-304 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/11r1xptp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_183602-11r1xptp/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_183711-uxhefaak
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sound-305
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/uxhefaak
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14b1d8b25a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run youthful-sound-305 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/uxhefaak
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_183711-uxhefaak/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_183831-pg2z19rd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-dust-306
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/pg2z19rd
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x150607092a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run pretty-dust-306 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/pg2z19rd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_183831-pg2z19rd/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_183950-04y2x773
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-smoke-307
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/04y2x773
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1544a3b55a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run olive-smoke-307 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/04y2x773
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_183950-04y2x773/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_184108-4d23t249
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-microwave-308
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4d23t249
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14989e5d5a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run kind-microwave-308 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4d23t249
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_184108-4d23t249/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_184224-r7j7q1ou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-microwave-309
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/r7j7q1ou
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x152803f70d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run robust-microwave-309 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/r7j7q1ou
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_184224-r7j7q1ou/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_184340-kfgim328
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-universe-310
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/kfgim328
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15411f48fa30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run quiet-universe-310 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/kfgim328
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_184340-kfgim328/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_184458-rfghbz1b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-water-311
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/rfghbz1b
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14c9061eea90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run earnest-water-311 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/rfghbz1b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_184458-rfghbz1b/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_184606-cgwqde4a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sound-312
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/cgwqde4a
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x151f9f32aa30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run honest-sound-312 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/cgwqde4a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_184606-cgwqde4a/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_184723-sjr9v81p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-glitter-313
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/sjr9v81p
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14e667dc6a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run jumping-glitter-313 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/sjr9v81p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_184723-sjr9v81p/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_184841-n7idmvgt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-blaze-314
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/n7idmvgt
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14a3fff4da60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run vital-blaze-314 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/n7idmvgt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_184841-n7idmvgt/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_184956-inkv2kug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-dawn-315
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/inkv2kug
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1527a06afa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run spring-dawn-315 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/inkv2kug
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_184956-inkv2kug/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_185113-udrns6t6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-wildflower-316
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/udrns6t6
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1487e8eb1a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run lucky-wildflower-316 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/udrns6t6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_185113-udrns6t6/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_185228-zc2xloyp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-serenity-317
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/zc2xloyp
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14a3dc20fd00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.383 MB uploadedwandb: | 0.385 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run spring-serenity-317 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/zc2xloyp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_185228-zc2xloyp/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_185346-z7519ba1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-wave-318
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/z7519ba1
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149df0a31a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run likely-wave-318 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/z7519ba1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_185346-z7519ba1/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_185502-8ga04soh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-firefly-319
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/8ga04soh
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148754beaa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run snowy-firefly-319 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/8ga04soh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_185502-8ga04soh/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_185624-lvx16ol3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-tree-320
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/lvx16ol3
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14973e21ca30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run confused-tree-320 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/lvx16ol3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_185624-lvx16ol3/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_185732-snp7yeds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-waterfall-321
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/snp7yeds
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14ad5a7d4a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run fine-waterfall-321 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/snp7yeds
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_185732-snp7yeds/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_185849-4kahsrgy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-salad-322
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4kahsrgy
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14d0d45d2a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run distinctive-salad-322 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4kahsrgy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_185849-4kahsrgy/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_190003-tc4qgdwp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-microwave-323
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/tc4qgdwp
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149ea547da90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run devoted-microwave-323 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/tc4qgdwp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_190003-tc4qgdwp/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_190121-yic6ewao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-field-324
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/yic6ewao
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1467ca8e2a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run eager-field-324 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/yic6ewao
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_190121-yic6ewao/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_190237-7vcf2fst
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-forest-325
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7vcf2fst
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146828894a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run earthy-forest-325 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7vcf2fst
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_190237-7vcf2fst/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_190351-t2osrjkn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-universe-326
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/t2osrjkn
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x151a0a410a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.383 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run major-universe-326 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/t2osrjkn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_190351-t2osrjkn/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_190506-3torcrku
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-monkey-327
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/3torcrku
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15008c5cda60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run crimson-monkey-327 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/3torcrku
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_190506-3torcrku/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_190620-c9ic9a5r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sunset-328
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/c9ic9a5r
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1535ea56aa30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run glorious-sunset-328 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/c9ic9a5r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_190620-c9ic9a5r/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_190736-wpn947ms
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-dream-329
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wpn947ms
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14db41621a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run curious-dream-329 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wpn947ms
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_190736-wpn947ms/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_190851-y8on67v7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-bird-330
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/y8on67v7
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14ac96abaa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run cerulean-bird-330 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/y8on67v7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_190851-y8on67v7/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_191008-ilc55ntu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-bee-331
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ilc55ntu
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1522180aea90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run soft-bee-331 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ilc55ntu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_191008-ilc55ntu/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_191124-bpa3mm7k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-cherry-332
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/bpa3mm7k
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x152b71715a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.379 MB of 0.389 MB uploadedwandb: \ 0.385 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run cool-cherry-332 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/bpa3mm7k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_191124-bpa3mm7k/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_191242-7455g13u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-plasma-333
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7455g13u
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15211bb54a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.387 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run neat-plasma-333 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7455g13u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_191242-7455g13u/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_191357-n1ekfx17
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-bush-334
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/n1ekfx17
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15285d96fa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.383 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run effortless-bush-334 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/n1ekfx17
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_191357-n1ekfx17/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_191507-3cu3qsjb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-thunder-335
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/3cu3qsjb
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x152b52342a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run stellar-thunder-335 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/3cu3qsjb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_191507-3cu3qsjb/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_191624-4wicbe81
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-music-336
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4wicbe81
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1479d60daa00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.387 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run treasured-music-336 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4wicbe81
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_191624-4wicbe81/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_191742-u4zobha2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sound-337
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/u4zobha2
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x154092039a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run hearty-sound-337 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/u4zobha2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_191742-u4zobha2/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_191851-y27zntic
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-yogurt-338
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/y27zntic
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x155161f56a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run grateful-yogurt-338 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/y27zntic
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_191851-y27zntic/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_192007-yz3htnir
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-pine-339
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/yz3htnir
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14d1d21e5a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.385 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run apricot-pine-339 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/yz3htnir
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_192007-yz3htnir/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_192125-kmt0ogoo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-wave-340
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/kmt0ogoo
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146c44717d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.379 MB of 0.389 MB uploadedwandb: / 0.385 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run northern-wave-340 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/kmt0ogoo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_192125-kmt0ogoo/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_192246-um4yeysv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-planet-341
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/um4yeysv
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14e9415d7a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.380 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run amber-planet-341 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/um4yeysv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_192246-um4yeysv/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_192405-7qioxhum
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-water-342
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7qioxhum
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1485edfd6a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.387 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run youthful-water-342 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7qioxhum
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_192405-7qioxhum/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_192521-k5rb2lvd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-spaceship-343
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/k5rb2lvd
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14dab2325a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.385 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run eager-spaceship-343 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/k5rb2lvd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_192521-k5rb2lvd/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_192641-l6eb1owf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-morning-344
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/l6eb1owf
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14da2ae10a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.387 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run youthful-morning-344 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/l6eb1owf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_192641-l6eb1owf/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_192800-dpl1ako4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-monkey-345
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/dpl1ako4
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14ff6ffcba30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.381 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run super-monkey-345 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/dpl1ako4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_192800-dpl1ako4/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_192918-vv0xfa68
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-durian-346
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vv0xfa68
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14950a395a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: | 0.385 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run feasible-durian-346 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vv0xfa68
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_192918-vv0xfa68/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_193037-v6p9wg5p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-gorge-347
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/v6p9wg5p
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14f4e0a13a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run genial-gorge-347 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/v6p9wg5p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_193037-v6p9wg5p/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_193143-xut8mrpe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-field-348
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/xut8mrpe
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14e0a22e0a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.384 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run morning-field-348 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/xut8mrpe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_193143-xut8mrpe/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_193304-034t8rgn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-paper-349
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/034t8rgn
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14a9a32ada90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.381 MB of 0.389 MB uploadedwandb: / 0.385 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run youthful-paper-349 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/034t8rgn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_193304-034t8rgn/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_193424-r7vvgfgx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-monkey-350
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/r7vvgfgx
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1521edeb1a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.383 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run rose-monkey-350 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/r7vvgfgx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_193424-r7vvgfgx/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_193544-c4o4c393
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-feather-351
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/c4o4c393
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149db0ec1a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run fluent-feather-351 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/c4o4c393
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_193544-c4o4c393/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_193706-tdxqq3rq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-field-352
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/tdxqq3rq
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14fdeca3ea60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.383 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run lilac-field-352 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/tdxqq3rq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_193706-tdxqq3rq/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_193821-n4lvv089
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-bird-353
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/n4lvv089
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x154ea6b2ca60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.387 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run gallant-bird-353 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/n4lvv089
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_193821-n4lvv089/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_193940-l0cd0lul
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-glitter-354
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/l0cd0lul
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14a5b021dd00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.379 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run worldly-glitter-354 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/l0cd0lul
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_193940-l0cd0lul/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_194054-nmvyd69i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-pyramid-355
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nmvyd69i
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14856791aa60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.387 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run silvery-pyramid-355 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nmvyd69i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_194054-nmvyd69i/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_194213-daro8lsi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-breeze-356
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/daro8lsi
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14c8660e4a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.379 MB of 0.389 MB uploadedwandb: | 0.386 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run vibrant-breeze-356 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/daro8lsi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_194213-daro8lsi/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_194333-wao99mfv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-lake-357
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wao99mfv
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148dbe2a0a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.383 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run mild-lake-357 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wao99mfv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_194333-wao99mfv/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_194453-yol8le2h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-disco-358
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/yol8le2h
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x147fc10e2a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run fluent-disco-358 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/yol8le2h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_194453-yol8le2h/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_194616-4h8j684p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-hill-359
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4h8j684p
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.0001, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15191c84aa60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2519
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25185
wandb: 
wandb: üöÄ View run dutiful-hill-359 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4h8j684p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_194616-4h8j684p/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_194736-5ujily8d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-resonance-360
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/5ujily8d
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1518aa4d6a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.388 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run fine-resonance-360 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/5ujily8d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_194736-5ujily8d/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_194857-xt8993xu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-forest-361
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/xt8993xu
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14b8b2525a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.386 MB of 0.389 MB uploadedwandb: | 0.386 MB of 0.389 MB uploadedwandb: / 0.386 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run trim-forest-361 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/xt8993xu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_194857-xt8993xu/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_195017-ts5m93ho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sea-362
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ts5m93ho
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1483b535ca30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run feasible-sea-362 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ts5m93ho
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_195017-ts5m93ho/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_195134-yf9gjeie
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sound-363
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/yf9gjeie
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14621e7a9a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.383 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.385 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run solar-sound-363 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/yf9gjeie
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_195134-yf9gjeie/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_195257-kxik26zp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-cloud-364
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/kxik26zp
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x151f72edba30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run solar-cloud-364 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/kxik26zp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_195257-kxik26zp/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_195406-accdpsu6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-snowflake-365
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/accdpsu6
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14b9c8a82a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run revived-snowflake-365 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/accdpsu6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_195406-accdpsu6/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_195524-9ea4c53h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-capybara-366
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/9ea4c53h
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1550ea0d2a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run silver-capybara-366 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/9ea4c53h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_195524-9ea4c53h/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_195630-xbeaznu1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-violet-367
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/xbeaznu1
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x145b76d96a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run electric-violet-367 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/xbeaznu1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_195630-xbeaznu1/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_195751-hzqqehrk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-pond-368
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hzqqehrk
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x145ebf411a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run splendid-pond-368 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hzqqehrk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_195751-hzqqehrk/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_195910-jlsqnyth
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-glade-369
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/jlsqnyth
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14e58e4c6a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run morning-glade-369 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/jlsqnyth
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_195910-jlsqnyth/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_200027-vg4ub3nr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-cherry-370
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vg4ub3nr
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1457087fad00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.381 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run rare-cherry-370 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vg4ub3nr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_200027-vg4ub3nr/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_200139-0dpkjxqs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-dust-371
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/0dpkjxqs
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14e689fb9a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.381 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run unique-dust-371 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/0dpkjxqs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_200139-0dpkjxqs/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_200258-eqc325n2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-glade-372
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/eqc325n2
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14be987c5a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run elated-glade-372 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/eqc325n2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_200258-eqc325n2/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_200406-rq2bgn91
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-dragon-373
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/rq2bgn91
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15039943cd00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.383 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run peach-dragon-373 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/rq2bgn91
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_200406-rq2bgn91/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_200526-obznwjh5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-night-374
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/obznwjh5
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x154576d19a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.385 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run tough-night-374 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/obznwjh5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_200526-obznwjh5/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_200645-t5w0y2vo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-pyramid-375
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/t5w0y2vo
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1532a0172a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.383 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run super-pyramid-375 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/t5w0y2vo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_200645-t5w0y2vo/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_200759-1hh3blkz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-water-376
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/1hh3blkz
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1485b119da30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.383 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.383 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run ancient-water-376 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/1hh3blkz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_200759-1hh3blkz/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_200916-03z4yyp8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-monkey-377
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/03z4yyp8
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x150d7a983a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run revived-monkey-377 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/03z4yyp8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_200916-03z4yyp8/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_201029-7m2dmu73
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-snowball-378
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7m2dmu73
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146113e10a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run astral-snowball-378 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7m2dmu73
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_201029-7m2dmu73/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_201150-vam5hlvg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-haze-379
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vam5hlvg
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x153a8d20ba30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run crimson-haze-379 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vam5hlvg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_201150-vam5hlvg/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_201258-1gyxxswk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-gorge-380
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/1gyxxswk
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14c83693ea30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run trim-gorge-380 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/1gyxxswk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_201258-1gyxxswk/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_201413-zz0v7wuy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-darkness-381
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/zz0v7wuy
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14f7345e7d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run good-darkness-381 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/zz0v7wuy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_201413-zz0v7wuy/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_201522-rycc8n3z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-energy-382
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/rycc8n3z
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149a029b1a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run atomic-energy-382 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/rycc8n3z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_201522-rycc8n3z/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_201645-evn26m5r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-spaceship-383
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/evn26m5r
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149d18283a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.385 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run pleasant-spaceship-383 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/evn26m5r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_201645-evn26m5r/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_201800-kb0k8ac2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-water-384
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/kb0k8ac2
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15497d2f7a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run cerulean-water-384 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/kb0k8ac2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_201800-kb0k8ac2/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_201916-vb3qeuhq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-disco-386
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vb3qeuhq
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x153b0a8daa30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run dauntless-disco-386 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vb3qeuhq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_201916-vb3qeuhq/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_202033-7dp4ig8t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-valley-387
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7dp4ig8t
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14f2aac06a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.379 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run bright-valley-387 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7dp4ig8t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_202033-7dp4ig8t/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_202145-pjiihasf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-shape-388
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/pjiihasf
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x153b41f65a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run visionary-shape-388 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/pjiihasf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_202145-pjiihasf/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_202307-21m63ia5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-aardvark-391
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/21m63ia5
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14ac2de85a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run amber-aardvark-391 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/21m63ia5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_202307-21m63ia5/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_202418-bx3nrxvf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-dew-393
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/bx3nrxvf
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14aac90b6a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: | 0.385 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run astral-dew-393 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/bx3nrxvf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_202418-bx3nrxvf/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_202536-mfx5gvje
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sky-395
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/mfx5gvje
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148ef860aa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.379 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run clean-sky-395 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/mfx5gvje
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_202536-mfx5gvje/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_202655-rhry51gr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-leaf-397
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/rhry51gr
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146bfbe82a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: | 0.385 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run fine-leaf-397 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/rhry51gr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_202655-rhry51gr/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_202816-t85cch74
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-spaceship-399
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/t85cch74
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14caf50ada60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run peach-spaceship-399 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/t85cch74
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_202816-t85cch74/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_202933-i6w85ofy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-shadow-401
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/i6w85ofy
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14a662342a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run smart-shadow-401 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/i6w85ofy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_202933-i6w85ofy/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_203048-p8spu4ev
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-wave-403
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/p8spu4ev
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14631988fa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run brisk-wave-403 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/p8spu4ev
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_203048-p8spu4ev/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_203201-t6198nsh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-planet-405
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/t6198nsh
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15361450aa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run stoic-planet-405 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/t6198nsh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_203201-t6198nsh/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_203317-83uqysav
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-water-406
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/83uqysav
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14f3c4b35a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run ethereal-water-406 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/83uqysav
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_203317-83uqysav/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_203433-itjd39rs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-salad-408
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/itjd39rs
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14d0ca2e9a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.383 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run iconic-salad-408 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/itjd39rs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_203433-itjd39rs/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_203553-phbxwiwl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-disco-410
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/phbxwiwl
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14f20cb7aa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.379 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run breezy-disco-410 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/phbxwiwl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_203553-phbxwiwl/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_203709-4245u6cx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-donkey-412
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4245u6cx
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14f8657d8a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run skilled-donkey-412 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4245u6cx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_203709-4245u6cx/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_203824-8pejapuy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-river-414
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/8pejapuy
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x151b3c374a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.383 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run smooth-river-414 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/8pejapuy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_203824-8pejapuy/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_203941-u0ha0ksl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-water-416
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/u0ha0ksl
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14b802e4da90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.379 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run good-water-416 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/u0ha0ksl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_203941-u0ha0ksl/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_204057-nzmjgwlf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-salad-418
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nzmjgwlf
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1531d5254a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.383 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run hearty-salad-418 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nzmjgwlf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_204057-nzmjgwlf/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_204212-dblz6830
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-wind-420
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/dblz6830
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14ce78c16a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run stoic-wind-420 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/dblz6830
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_204212-dblz6830/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_204330-qooi931e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-plasma-422
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/qooi931e
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x151a5113ca60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run curious-plasma-422 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/qooi931e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_204330-qooi931e/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_204447-wffuyd0l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-butterfly-424
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wffuyd0l
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1519e32d5a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.385 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run decent-butterfly-424 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wffuyd0l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_204447-wffuyd0l/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_204604-i1xmhsfq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-elevator-425
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/i1xmhsfq
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x150725104a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run fanciful-elevator-425 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/i1xmhsfq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_204604-i1xmhsfq/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_204719-tgp3ognu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-surf-427
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/tgp3ognu
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14c3a9b4ba30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run tough-surf-427 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/tgp3ognu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_204719-tgp3ognu/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_204834-1p4qeswf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-water-429
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/1p4qeswf
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x153f14d0fa60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.383 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run wild-water-429 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/1p4qeswf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_204834-1p4qeswf/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_204950-w206jrj6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-dream-431
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/w206jrj6
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146c3b5eda90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.383 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run rosy-dream-431 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/w206jrj6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_204950-w206jrj6/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_205104-gigi6o7q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sound-433
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/gigi6o7q
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14d030b62a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run wild-sound-433 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/gigi6o7q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_205104-gigi6o7q/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_205223-sdemwqns
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-bush-435
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/sdemwqns
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1547036f0a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run floral-bush-435 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/sdemwqns
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_205223-sdemwqns/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_205340-4c6eah87
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-violet-437
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4c6eah87
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x145f06ec9a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run golden-violet-437 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4c6eah87
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_205340-4c6eah87/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_205456-pc3tp2o5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-darkness-439
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/pc3tp2o5
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1494a9321a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run charmed-darkness-439 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/pc3tp2o5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_205456-pc3tp2o5/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_205617-yqzjjugt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-cloud-441
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/yqzjjugt
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146ceac3ea90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run misunderstood-cloud-441 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/yqzjjugt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_205617-yqzjjugt/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_205733-59k3sajd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-serenity-443
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/59k3sajd
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15335db57a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run daily-serenity-443 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/59k3sajd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_205733-59k3sajd/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_205849-i1maq0g1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-silence-445
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/i1maq0g1
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14e5ff546a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run divine-silence-445 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/i1maq0g1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_205849-i1maq0g1/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_210006-94fw4qsd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-resonance-447
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/94fw4qsd
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14b236151a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.385 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run young-resonance-447 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/94fw4qsd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_210006-94fw4qsd/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_210118-gb8dl29x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sea-449
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/gb8dl29x
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15300d378a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run lemon-sea-449 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/gb8dl29x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_210118-gb8dl29x/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_210233-9hst079c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-night-451
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/9hst079c
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x154e454e0d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run dark-night-451 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/9hst079c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_210233-9hst079c/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_210349-ze17ojfn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-bush-453
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ze17ojfn
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1547e0769a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run graceful-bush-453 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ze17ojfn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_210349-ze17ojfn/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_210509-ddb4nvoi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-butterfly-455
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ddb4nvoi
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1550ec1d0a00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.387 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run whole-butterfly-455 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ddb4nvoi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_210509-ddb4nvoi/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_210619-x4rci0in
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-night-457
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/x4rci0in
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1483bd0c8a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run valiant-night-457 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/x4rci0in
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_210619-x4rci0in/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_210734-ok0njy9z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-brook-459
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ok0njy9z
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148e31512a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run bright-brook-459 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ok0njy9z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_210734-ok0njy9z/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_210849-ypcb7kbl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sun-461
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ypcb7kbl
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14e982948a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run jumping-sun-461 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ypcb7kbl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_210849-ypcb7kbl/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_211008-fmgta05n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-river-463
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/fmgta05n
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1535e53d6a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run denim-river-463 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/fmgta05n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_211008-fmgta05n/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_211125-irhngfrd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-plasma-465
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/irhngfrd
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1492e0ac0a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.381 MB of 0.389 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run stellar-plasma-465 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/irhngfrd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_211125-irhngfrd/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_211238-n287fs82
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-waterfall-467
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/n287fs82
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x153408978a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run swept-waterfall-467 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/n287fs82
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_211238-n287fs82/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_211358-jrzajawj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-snowball-469
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/jrzajawj
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14bb8921ba90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run light-snowball-469 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/jrzajawj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_211358-jrzajawj/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_211513-fp8cho66
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-snowflake-471
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/fp8cho66
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149e675ffa30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run trim-snowflake-471 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/fp8cho66
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_211513-fp8cho66/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_211633-wzzubkf7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-leaf-473
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wzzubkf7
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14eb13dffa60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run peach-leaf-473 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wzzubkf7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_211633-wzzubkf7/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_211748-mgd6ujlf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-darkness-475
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/mgd6ujlf
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14d43a6a8a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run hearty-darkness-475 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/mgd6ujlf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_211748-mgd6ujlf/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_211906-crqc13vj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sea-477
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/crqc13vj
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1507f60c4a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run deft-sea-477 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/crqc13vj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_211906-crqc13vj/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_212025-knvv2bsz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-terrain-479
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/knvv2bsz
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x154444c81a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run stellar-terrain-479 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/knvv2bsz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_212025-knvv2bsz/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_212139-4wd5s5g5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-haze-481
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4wd5s5g5
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1522c3745ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run quiet-haze-481 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4wd5s5g5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_212139-4wd5s5g5/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_212252-fubz0zyk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-wind-483
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/fubz0zyk
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x147120263a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.379 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run rural-wind-483 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/fubz0zyk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_212252-fubz0zyk/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_212412-6bkslhdm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-breeze-485
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/6bkslhdm
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x154aab57aac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run bright-breeze-485 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/6bkslhdm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_212412-6bkslhdm/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_212532-q2zs868w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-silence-487
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/q2zs868w
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x147f47f7eac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.383 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run feasible-silence-487 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/q2zs868w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_212532-q2zs868w/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_212648-dz29smlf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-breeze-489
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/dz29smlf
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1455d44a8ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run easy-breeze-489 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/dz29smlf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_212648-dz29smlf/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_212802-2ke77vsn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-puddle-491
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/2ke77vsn
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x152db2ba9ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.387 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run classic-puddle-491 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/2ke77vsn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_212802-2ke77vsn/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_212924-zaqp06e4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-yogurt-493
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/zaqp06e4
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14d2bedfbac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.385 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run soft-yogurt-493 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/zaqp06e4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_212924-zaqp06e4/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_213042-mc01f59a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-haze-495
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/mc01f59a
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14bb50f42ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.379 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run misty-haze-495 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/mc01f59a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_213042-mc01f59a/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_213200-kvkh4xkj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-durian-498
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/kvkh4xkj
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149d6d525a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run icy-durian-498 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/kvkh4xkj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_213200-kvkh4xkj/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_213318-8fmxjrfo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-brook-500
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/8fmxjrfo
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14cbcb209ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run glamorous-brook-500 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/8fmxjrfo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_213318-8fmxjrfo/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_213431-nbv3om95
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-snowflake-502
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nbv3om95
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148136bf7a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.387 MB of 0.389 MB uploadedwandb: / 0.387 MB of 0.389 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.387 MB of 0.389 MB uploadedwandb: | 0.387 MB of 0.389 MB uploadedwandb: / 0.387 MB of 0.389 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.387 MB of 0.389 MB uploadedwandb: | 0.387 MB of 0.389 MB uploadedwandb: / 0.387 MB of 0.389 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.387 MB of 0.389 MB uploadedwandb: | 0.387 MB of 0.389 MB uploadedwandb: / 0.387 MB of 0.389 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.387 MB of 0.389 MB uploadedwandb: | 0.387 MB of 0.389 MB uploadedwandb: / 0.387 MB of 0.389 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.387 MB of 0.389 MB uploadedwandb: | 0.387 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run glowing-snowflake-502 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nbv3om95
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_213431-nbv3om95/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_213612-tkmnwsgt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-blaze-504
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/tkmnwsgt
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1479951b8a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run silver-blaze-504 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/tkmnwsgt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_213612-tkmnwsgt/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_213729-5d96h7o0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sun-506
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/5d96h7o0
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1529fc17bac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run cosmic-sun-506 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/5d96h7o0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_213729-5d96h7o0/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_213848-rmrz4xu6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-cloud-508
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/rmrz4xu6
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146af90cba90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run snowy-cloud-508 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/rmrz4xu6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_213848-rmrz4xu6/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_214007-gy0ofum5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-shadow-510
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/gy0ofum5
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x150e80171a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.388 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run jolly-shadow-510 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/gy0ofum5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_214007-gy0ofum5/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_214126-19svobq9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-cosmos-513
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/19svobq9
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x145fa487da60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run morning-cosmos-513 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/19svobq9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_214126-19svobq9/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_214244-5t5tk75n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-jazz-515
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/5t5tk75n
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149c73aafac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run dry-jazz-515 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/5t5tk75n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_214244-5t5tk75n/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_214400-87pt3rx2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-wood-517
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/87pt3rx2
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14cd82e47ac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run celestial-wood-517 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/87pt3rx2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_214400-87pt3rx2/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_214517-b3s536fq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-dawn-519
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/b3s536fq
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15194e98bac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run fallen-dawn-519 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/b3s536fq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_214517-b3s536fq/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_214636-95ewxsqi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-bush-520
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/95ewxsqi
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1553d040eac0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.383 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run devout-bush-520 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/95ewxsqi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_214636-95ewxsqi/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_214749-e4og6nq8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-dragon-521
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/e4og6nq8
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x145c5901ca90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run visionary-dragon-521 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/e4og6nq8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_214749-e4og6nq8/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_214905-awhm9wz8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-valley-522
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/awhm9wz8
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1499b616aa60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run vague-valley-522 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/awhm9wz8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_214905-awhm9wz8/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_215021-ptgbq7y7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-haze-523
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ptgbq7y7
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146d46db9a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.383 MB uploadedwandb: | 0.381 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run silvery-haze-523 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ptgbq7y7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_215021-ptgbq7y7/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_215131-j06d0mxy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-fire-524
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/j06d0mxy
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14ada3e23a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2556
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25556
wandb: 
wandb: üöÄ View run pleasant-fire-524 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/j06d0mxy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_215131-j06d0mxy/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_215238-xr9dqo8e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-donkey-525
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/xr9dqo8e
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1465d55a5a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26296
wandb: 
wandb: üöÄ View run iconic-donkey-525 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/xr9dqo8e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_215238-xr9dqo8e/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_215355-chm1vxpt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-river-526
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/chm1vxpt
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.01, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14bcf62dba60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2481
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.24815
wandb: 
wandb: üöÄ View run rose-river-526 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/chm1vxpt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_215355-chm1vxpt/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_215512-f3v44mrk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-pond-527
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/f3v44mrk
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x145fbdc6fa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run olive-pond-527 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/f3v44mrk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_215512-f3v44mrk/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_215628-fg26tq17
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-field-528
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/fg26tq17
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1464add24a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.383 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run effortless-field-528 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/fg26tq17
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_215628-fg26tq17/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_215737-vt8kkka9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-deluge-529
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vt8kkka9
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x153d8fd95a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run true-deluge-529 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vt8kkka9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_215737-vt8kkka9/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_215853-g8ifqgsm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-wildflower-530
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/g8ifqgsm
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14daa1d0ea60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run fresh-wildflower-530 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/g8ifqgsm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_215853-g8ifqgsm/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_220010-e6sw48vd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-snowball-531
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/e6sw48vd
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1518b2b3fa60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run rare-snowball-531 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/e6sw48vd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_220010-e6sw48vd/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_220125-wbbmugq9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-thunder-532
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wbbmugq9
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1520246c3a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run solar-thunder-532 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wbbmugq9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_220125-wbbmugq9/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_220239-0pe1hrvp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-aardvark-533
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/0pe1hrvp
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x153b78de0a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run cosmic-aardvark-533 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/0pe1hrvp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_220239-0pe1hrvp/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_220352-j1ln5ir3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-fog-534
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/j1ln5ir3
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1514d51f0a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run honest-fog-534 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/j1ln5ir3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_220352-j1ln5ir3/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_220504-fa3c8iym
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-violet-535
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/fa3c8iym
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14bc61daea90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run sleek-violet-535 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/fa3c8iym
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_220504-fa3c8iym/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_220617-r3buljpx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sun-536
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/r3buljpx
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x145d1caeba90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run northern-sun-536 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/r3buljpx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_220617-r3buljpx/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_220734-6o21d8kd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-dew-537
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/6o21d8kd
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146d3e27ea90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run spring-dew-537 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/6o21d8kd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_220734-6o21d8kd/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_220847-juy7qzpn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-eon-538
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/juy7qzpn
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1526a498ba90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run devout-eon-538 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/juy7qzpn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_220847-juy7qzpn/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_221003-n62x7f5n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-dew-539
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/n62x7f5n
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15238c87da90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run dainty-dew-539 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/n62x7f5n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_221003-n62x7f5n/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_221120-7brm1blt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-glade-540
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7brm1blt
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14c5572d3a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.388 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run dandy-glade-540 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7brm1blt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_221120-7brm1blt/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_221233-zrk5jg6c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-cloud-541
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/zrk5jg6c
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x152ec901ba30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run dulcet-cloud-541 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/zrk5jg6c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_221233-zrk5jg6c/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_221349-z32dhk1l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-firebrand-542
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/z32dhk1l
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15135fba1a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run dutiful-firebrand-542 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/z32dhk1l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_221349-z32dhk1l/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_221507-8m8kpxgi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-water-543
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/8m8kpxgi
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14bd7156ea60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run visionary-water-543 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/8m8kpxgi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_221507-8m8kpxgi/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_221625-437uz4cn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-pyramid-544
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/437uz4cn
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14f56a7efa60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run twilight-pyramid-544 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/437uz4cn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_221625-437uz4cn/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_221744-r7rbpox1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-haze-545
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/r7rbpox1
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14991975aa60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.383 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run true-haze-545 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/r7rbpox1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_221744-r7rbpox1/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_221901-dtajs2w7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-armadillo-546
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/dtajs2w7
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14d5d7d30a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run lively-armadillo-546 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/dtajs2w7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_221901-dtajs2w7/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_222017-lrygtum4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-bee-547
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/lrygtum4
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14e0985f5a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.385 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run generous-bee-547 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/lrygtum4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_222017-lrygtum4/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_222126-9vplij00
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-elevator-548
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/9vplij00
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x152ab9b31a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run rich-elevator-548 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/9vplij00
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_222126-9vplij00/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_222237-my4avpqr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-fire-549
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/my4avpqr
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14a55613ea60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run crisp-fire-549 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/my4avpqr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_222237-my4avpqr/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_222354-z5jvdi40
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-bee-550
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/z5jvdi40
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x152b0b229a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run autumn-bee-550 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/z5jvdi40
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_222354-z5jvdi40/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_222507-vehum6d4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-bush-551
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vehum6d4
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14ba92acea30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run cerulean-bush-551 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vehum6d4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_222507-vehum6d4/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_222625-2hgubeh8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-shape-552
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/2hgubeh8
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15479af83a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run unique-shape-552 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/2hgubeh8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_222625-2hgubeh8/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_222745-ijsrjvzj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sunset-553
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ijsrjvzj
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x153b487c8a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run denim-sunset-553 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ijsrjvzj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_222745-ijsrjvzj/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_222903-j3mvg70t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-dream-554
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/j3mvg70t
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1548318c1a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run vibrant-dream-554 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/j3mvg70t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_222903-j3mvg70t/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_223018-5ioxaw6v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-glitter-555
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/5ioxaw6v
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1538ad6cca30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run soft-glitter-555 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/5ioxaw6v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_223018-5ioxaw6v/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_223133-eaj13j5f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-eon-556
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/eaj13j5f
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15069cecaa60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run spring-eon-556 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/eaj13j5f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_223133-eaj13j5f/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_223249-4yngk5nd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-dust-557
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4yngk5nd
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x153e8cf3ea30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.381 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run gentle-dust-557 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4yngk5nd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_223249-4yngk5nd/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_223416-78bomux1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-glade-558
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/78bomux1
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149165b8ca90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run prime-glade-558 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/78bomux1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_223416-78bomux1/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_223525-j2m0r021
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-elevator-559
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/j2m0r021
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1483fb4d9a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.383 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run peachy-elevator-559 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/j2m0r021
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_223525-j2m0r021/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_223644-luardb4p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-serenity-560
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/luardb4p
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148c79c22a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run dauntless-serenity-560 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/luardb4p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_223644-luardb4p/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_223751-3os8b65j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-pyramid-561
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/3os8b65j
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x147566ba7a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run astral-pyramid-561 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/3os8b65j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_223751-3os8b65j/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_223906-ski3dmsp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-yogurt-562
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ski3dmsp
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149f442c4a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run frosty-yogurt-562 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ski3dmsp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_223906-ski3dmsp/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_224014-82jlvj57
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-butterfly-563
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/82jlvj57
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146736409a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run revived-butterfly-563 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/82jlvj57
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_224014-82jlvj57/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_224134-fuet4w3s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-voice-564
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/fuet4w3s
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1477a0ff8a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run gallant-voice-564 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/fuet4w3s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_224134-fuet4w3s/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_224253-if0jrs8a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-donkey-565
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/if0jrs8a
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x152f7dd83a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run silver-donkey-565 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/if0jrs8a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_224253-if0jrs8a/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_224410-4p3jrd1q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sky-566
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4p3jrd1q
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x151ee43a5a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run glowing-sky-566 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4p3jrd1q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_224410-4p3jrd1q/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_224529-33nq3inu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-snowflake-567
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/33nq3inu
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15472b578a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run lilac-snowflake-567 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/33nq3inu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_224529-33nq3inu/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_224645-r1x0w3xj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-wildflower-568
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/r1x0w3xj
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x145d7ea22a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run dulcet-wildflower-568 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/r1x0w3xj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_224645-r1x0w3xj/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_224804-hnrkfwf0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sound-569
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hnrkfwf0
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14b9b520ea00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run dark-sound-569 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hnrkfwf0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_224804-hnrkfwf0/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_224917-a1cno3p3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-pine-570
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/a1cno3p3
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15057dcdba90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.383 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run lilac-pine-570 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/a1cno3p3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_224917-a1cno3p3/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_225036-d0uidj75
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-snowball-571
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/d0uidj75
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1516ed888a00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run spring-snowball-571 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/d0uidj75
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_225036-d0uidj75/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_225152-esk83scb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-armadillo-572
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/esk83scb
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14928729aa30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run vocal-armadillo-572 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/esk83scb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_225152-esk83scb/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_225305-12cqcc9f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-thunder-573
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/12cqcc9f
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149caeff7a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.381 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run swift-thunder-573 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/12cqcc9f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_225305-12cqcc9f/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_225420-q6rvkl5n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-snow-574
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/q6rvkl5n
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14f752e3ca90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run desert-snow-574 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/q6rvkl5n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_225420-q6rvkl5n/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_225538-wlxkuu4i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-plasma-575
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wlxkuu4i
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14d3df234a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run treasured-plasma-575 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wlxkuu4i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_225538-wlxkuu4i/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_225655-vrick25t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-shadow-576
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vrick25t
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148fa7318a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run eager-shadow-576 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vrick25t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_225655-vrick25t/logs
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_225815-3r8tazs7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-terrain-577
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/3r8tazs7
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x154464562a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run deep-terrain-577 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/3r8tazs7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_225815-3r8tazs7/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_225928-ui4ja33q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-star-578
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ui4ja33q
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x154804e51a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run dandy-star-578 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ui4ja33q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_225928-ui4ja33q/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_230049-qzhbr4wb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-smoke-579
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/qzhbr4wb
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149938a00a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run deep-smoke-579 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/qzhbr4wb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_230049-qzhbr4wb/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_230203-g1j8i2mg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-capybara-580
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/g1j8i2mg
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1476a5079a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run stellar-capybara-580 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/g1j8i2mg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_230203-g1j8i2mg/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_230320-kyzlmcpo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-hill-581
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/kyzlmcpo
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x147d9e17ba30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.381 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run wild-hill-581 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/kyzlmcpo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_230320-kyzlmcpo/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_230440-fe09aatf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-smoke-582
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/fe09aatf
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146f7f60ca90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run cosmic-smoke-582 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/fe09aatf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_230440-fe09aatf/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_230556-nwvz16nw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-leaf-583
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nwvz16nw
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148a0c570a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run fine-leaf-583 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nwvz16nw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_230556-nwvz16nw/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_230713-mtrjlqmo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-meadow-584
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/mtrjlqmo
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1542d1155a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.383 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run valiant-meadow-584 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/mtrjlqmo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_230713-mtrjlqmo/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_230827-6mqf94av
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-serenity-585
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/6mqf94av
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x151940ad5a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.383 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run sage-serenity-585 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/6mqf94av
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_230827-6mqf94av/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_230942-w449ws1d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-lake-586
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/w449ws1d
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15287d288a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run robust-lake-586 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/w449ws1d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_230942-w449ws1d/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_231100-nfqbil68
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-oath-587
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nfqbil68
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x150cbe069a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run fine-oath-587 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nfqbil68
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_231100-nfqbil68/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_231216-bzuaurdm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-plant-588
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/bzuaurdm
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14660e0a8a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run dutiful-plant-588 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/bzuaurdm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_231216-bzuaurdm/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_231332-u3hgmq93
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-dust-589
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/u3hgmq93
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148838f57d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.381 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run elated-dust-589 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/u3hgmq93
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_231332-u3hgmq93/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_231453-0mr3euwy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-universe-590
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/0mr3euwy
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15373161ca90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run zany-universe-590 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/0mr3euwy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_231453-0mr3euwy/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_231612-r8eg2000
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-plant-591
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/r8eg2000
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14e97e0b6a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run effortless-plant-591 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/r8eg2000
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_231612-r8eg2000/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_231731-2sx8hnsx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-yogurt-592
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/2sx8hnsx
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14960f76ea60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.383 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run crimson-yogurt-592 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/2sx8hnsx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_231731-2sx8hnsx/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_231848-7t8st57w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-lion-593
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7t8st57w
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14864ec76a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.387 MB of 0.389 MB uploadedwandb: | 0.387 MB of 0.389 MB uploadedwandb: / 0.387 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run hardy-lion-593 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7t8st57w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_231848-7t8st57w/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_232007-yurl6n1d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-jazz-594
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/yurl6n1d
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148c3c32aa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.385 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run wise-jazz-594 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/yurl6n1d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_232007-yurl6n1d/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_232123-nmoih5ad
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-wood-595
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nmoih5ad
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x145e2f45fa60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.379 MB of 0.389 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run elated-wood-595 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nmoih5ad
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_232123-nmoih5ad/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_232240-3q4v7jz1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-elevator-596
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/3q4v7jz1
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146d724b4a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run gallant-elevator-596 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/3q4v7jz1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_232240-3q4v7jz1/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_232356-n1fpveb6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-meadow-597
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/n1fpveb6
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14dc5ba54a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run cool-meadow-597 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/n1fpveb6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_232356-n1fpveb6/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_232515-dsfzz26b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-water-598
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/dsfzz26b
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1512af1f3a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run prime-water-598 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/dsfzz26b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_232515-dsfzz26b/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_232631-4u47k0ko
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sea-599
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4u47k0ko
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14d10801aa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.383 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run polished-sea-599 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4u47k0ko
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_232631-4u47k0ko/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_232747-od0ubozd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-puddle-600
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/od0ubozd
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x153e15ea2a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run glorious-puddle-600 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/od0ubozd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_232747-od0ubozd/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_232902-3flk4gdh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-cherry-601
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/3flk4gdh
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1468262a4a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run youthful-cherry-601 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/3flk4gdh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_232902-3flk4gdh/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_233019-5i4m75je
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-eon-602
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/5i4m75je
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14bd91435a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.385 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run polar-eon-602 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/5i4m75je
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_233019-5i4m75je/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_233138-fjh3jjn3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-cloud-603
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/fjh3jjn3
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14d23b35ba60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run rosy-cloud-603 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/fjh3jjn3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_233138-fjh3jjn3/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_233257-4saycwt7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-puddle-604
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4saycwt7
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15302166aa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run likely-puddle-604 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4saycwt7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_233257-4saycwt7/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_233412-0z997h3k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-thunder-605
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/0z997h3k
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14cffe8dfa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: | 0.385 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run apricot-thunder-605 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/0z997h3k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_233412-0z997h3k/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_233529-ruvruhjp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-cherry-606
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ruvruhjp
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.7, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146f27cd9a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run brisk-cherry-606 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ruvruhjp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_233529-ruvruhjp/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_233648-ticlicly
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-spaceship-607
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ticlicly
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x150c9fae5a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run floral-spaceship-607 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ticlicly
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_233648-ticlicly/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_233803-pbpz1j83
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-oath-608
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/pbpz1j83
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1482c1ae3a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run skilled-oath-608 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/pbpz1j83
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_233803-pbpz1j83/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_233922-4d8vmfvv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-brook-609
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4d8vmfvv
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14e4224cca60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run celestial-brook-609 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4d8vmfvv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_233922-4d8vmfvv/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_234039-u7mq6ppo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sun-610
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/u7mq6ppo
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.1, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1522e04d9a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run leafy-sun-610 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/u7mq6ppo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_234039-u7mq6ppo/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_234156-7h4n4vt9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-universe-611
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7h4n4vt9
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x154ad0084a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run autumn-universe-611 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7h4n4vt9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_234156-7h4n4vt9/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_234305-7uikee4c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-totem-612
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7uikee4c
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14c0e7242a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.388 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run comic-totem-612 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7uikee4c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_234305-7uikee4c/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_234425-nhzoe2y7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-haze-613
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nhzoe2y7
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14756f3a0a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.379 MB of 0.389 MB uploadedwandb: | 0.387 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run eternal-haze-613 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nhzoe2y7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_234425-nhzoe2y7/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_234537-v7kvwt7e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-dawn-614
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/v7kvwt7e
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.3, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14de67034a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run vocal-dawn-614 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/v7kvwt7e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_234537-v7kvwt7e/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_234655-wpp8k8zl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sky-615
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wpp8k8zl
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x151b9fdbea60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.383 MB uploadedwandb: / 0.381 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run vital-sky-615 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wpp8k8zl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_234655-wpp8k8zl/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_234815-7v9xninh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-mountain-616
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7v9xninh
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14d0e9dc3a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run likely-mountain-616 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7v9xninh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_234815-7v9xninh/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_234931-97784a8s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-pyramid-617
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/97784a8s
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x154012ce4a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run resilient-pyramid-617 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/97784a8s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_234931-97784a8s/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_235044-5velbjw3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-music-618
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/5velbjw3
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.5, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14b7d11c0a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run happy-music-618 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/5velbjw3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_235044-5velbjw3/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_235200-t6o92b09
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-galaxy-619
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/t6o92b09
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x154b2345ea90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.384 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run whole-galaxy-619 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/t6o92b09
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_235200-t6o92b09/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_235316-4k0ga5f6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-puddle-620
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4k0ga5f6
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14ba9f5a5a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run jumping-puddle-620 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/4k0ga5f6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_235316-4k0ga5f6/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_235436-jmoxg0ok
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-deluge-621
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/jmoxg0ok
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x154ed976fa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.387 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run ruby-deluge-621 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/jmoxg0ok
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_235436-jmoxg0ok/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_235553-l6rrhn7t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-durian-622
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/l6rrhn7t
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.7, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14cf27f02a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run sunny-durian-622 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/l6rrhn7t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_235553-l6rrhn7t/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_235716-56ip4z34
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-armadillo-623
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/56ip4z34
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14f0e2d90d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.3000
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.383 MB uploadedwandb: - 0.382 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.3
wandb: 
wandb: üöÄ View run zany-armadillo-623 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/56ip4z34
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_235716-56ip4z34/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_235830-cc8hc2k7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-salad-624
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/cc8hc2k7
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14b7218a0a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run fancy-salad-624 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/cc8hc2k7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_235830-cc8hc2k7/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240528_235945-l6iwk1oy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-dawn-625
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/l6iwk1oy
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x153b1e11ba60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2667
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.26667
wandb: 
wandb: üöÄ View run valiant-dawn-625 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/l6iwk1oy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_235945-l6iwk1oy/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_000059-quoz0tk1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-forest-626
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/quoz0tk1
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.9, alpha2=0.9, attack='tdgia', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='tdgia_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=0.1, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='tdgia_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x147fe08d7a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3037
===========Unlearning==========
Test accuracy of model: 0.2593
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.3037
wandb: Unlearned Model Test Accuracy 0.25926
wandb: 
wandb: üöÄ View run devoted-forest-626 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/quoz0tk1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_000059-quoz0tk1/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_000215-md4rbxqr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-butterfly-627
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/md4rbxqr
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14fb70421a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run hearty-butterfly-627 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/md4rbxqr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_000215-md4rbxqr/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_000325-li4kr618
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-salad-628
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/li4kr618
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14573c145a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3444
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.387 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.34444
wandb: 
wandb: üöÄ View run apricot-salad-628 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/li4kr618
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_000325-li4kr618/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_000434-ki21yw86
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-microwave-629
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ki21yw86
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x151fea686a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run astral-microwave-629 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ki21yw86
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_000434-ki21yw86/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_000549-vzp6q39j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-rain-630
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vzp6q39j
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.1, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14c7184b5a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.1222
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.12222
wandb: 
wandb: üöÄ View run lilac-rain-630 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/vzp6q39j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_000549-vzp6q39j/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_000704-nxe0fora
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-glitter-631
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nxe0fora
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14c6187cda30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run hardy-glitter-631 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/nxe0fora
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_000704-nxe0fora/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_000813-qsicvplh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-deluge-632
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/qsicvplh
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x150145de1a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3444
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.381 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.34444
wandb: 
wandb: üöÄ View run efficient-deluge-632 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/qsicvplh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_000813-qsicvplh/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_000930-st9lirlu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-rain-633
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/st9lirlu
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x153827586a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run comfy-rain-633 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/st9lirlu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_000930-st9lirlu/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_001043-woryk17u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-monkey-634
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/woryk17u
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.3, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x154435591a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.1222
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.381 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.12222
wandb: 
wandb: üöÄ View run polished-monkey-634 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/woryk17u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_001043-woryk17u/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_001200-casx75rp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-grass-635
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/casx75rp
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x145722461a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: | 0.381 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run glad-grass-635 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/casx75rp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_001200-casx75rp/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_001317-e9k6rq9r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-jazz-636
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/e9k6rq9r
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14e4d6d9ba60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3444
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.34444
wandb: 
wandb: üöÄ View run sleek-jazz-636 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/e9k6rq9r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_001317-e9k6rq9r/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_001433-lyx5euuf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-valley-637
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/lyx5euuf
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14eb79a3fa90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.383 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run confused-valley-637 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/lyx5euuf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_001433-lyx5euuf/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_001552-lgskq8k4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-smoke-638
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/lgskq8k4
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.5, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14645ef7fd00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.1222
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.12222
wandb: 
wandb: üöÄ View run summer-smoke-638 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/lgskq8k4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_001552-lgskq8k4/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_001703-8gar4z1p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-puddle-639
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/8gar4z1p
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15503866ea60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run rich-puddle-639 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/8gar4z1p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_001703-8gar4z1p/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_001818-if03pjyj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-butterfly-640
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/if03pjyj
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x147bdf223a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3444
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.34444
wandb: 
wandb: üöÄ View run warm-butterfly-640 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/if03pjyj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_001818-if03pjyj/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_001934-f2o1202p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-night-641
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/f2o1202p
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1546b6e01a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run solar-night-641 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/f2o1202p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_001934-f2o1202p/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_002050-7uuy6t7j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-night-642
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7uuy6t7j
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.7, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x15457ef28d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.1222
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.12222
wandb: 
wandb: üöÄ View run major-night-642 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7uuy6t7j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_002050-7uuy6t7j/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_002205-aa5m7aj3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-wildflower-643
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/aa5m7aj3
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149f5958ca60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.379 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run blooming-wildflower-643 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/aa5m7aj3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_002205-aa5m7aj3/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_002321-7lajcq0p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-firefly-644
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7lajcq0p
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14b3b1ec1a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3444
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.34444
wandb: 
wandb: üöÄ View run sage-firefly-644 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7lajcq0p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_002321-7lajcq0p/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_002435-mlm5igel
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-dragon-645
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/mlm5igel
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1514791e8a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.387 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run solar-dragon-645 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/mlm5igel
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_002435-mlm5igel/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_002552-v8bak840
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-dawn-646
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/v8bak840
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.1, alpha2=0.9, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x153d90d9aa30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.1222
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.12222
wandb: 
wandb: üöÄ View run hopeful-dawn-646 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/v8bak840
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_002552-v8bak840/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_002710-l3untl95
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sponge-647
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/l3untl95
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1542f6512a00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run polar-sponge-647 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/l3untl95
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_002710-l3untl95/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_002826-qufe2o7x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-cosmos-648
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/qufe2o7x
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x150e644bda60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3444
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.34444
wandb: 
wandb: üöÄ View run colorful-cosmos-648 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/qufe2o7x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_002826-qufe2o7x/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_002945-937ykw72
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-wildflower-649
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/937ykw72
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x146934b58a00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.385 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run jolly-wildflower-649 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/937ykw72
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_002945-937ykw72/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_003100-adzpzree
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-planet-650
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/adzpzree
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.1, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14d44d8c1a00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.1222
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.387 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.12222
wandb: 
wandb: üöÄ View run silvery-planet-650 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/adzpzree
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_003100-adzpzree/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_003215-8lrcsadi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-elevator-651
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/8lrcsadi
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x153803fd4a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run super-elevator-651 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/8lrcsadi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_003215-8lrcsadi/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_003334-58hxj6yu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-monkey-652
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/58hxj6yu
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x148011257a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3444
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.34444
wandb: 
wandb: üöÄ View run lucky-monkey-652 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/58hxj6yu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_003334-58hxj6yu/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_003442-lgot6xxh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-mountain-653
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/lgot6xxh
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14db20d1ea30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run stellar-mountain-653 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/lgot6xxh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_003442-lgot6xxh/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_003550-sydzqx7h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-lion-654
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/sydzqx7h
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.3, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x153814df7a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.1222
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.12222
wandb: 
wandb: üöÄ View run solar-lion-654 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/sydzqx7h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_003550-sydzqx7h/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_003707-i29hkeoo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-galaxy-655
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/i29hkeoo
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x150e69464a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.385 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run apricot-galaxy-655 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/i29hkeoo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_003707-i29hkeoo/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_003822-gjo3hr8p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-breeze-656
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/gjo3hr8p
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x147104836d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3444
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.34444
wandb: 
wandb: üöÄ View run fast-breeze-656 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/gjo3hr8p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_003822-gjo3hr8p/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_003941-bt4i10cm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-rain-657
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/bt4i10cm
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14eb5f151a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.385 MB uploadedwandb: | 0.387 MB of 0.389 MB uploadedwandb: / 0.387 MB of 0.389 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run wandering-rain-657 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/bt4i10cm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_003941-bt4i10cm/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_004101-12hqeub0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-hill-658
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/12hqeub0
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.5, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1463aab11a60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.1222
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.383 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.12222
wandb: 
wandb: üöÄ View run dark-hill-658 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/12hqeub0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_004101-12hqeub0/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_004217-wjveb60c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-galaxy-659
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wjveb60c
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x151835232a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run genial-galaxy-659 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wjveb60c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_004217-wjveb60c/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_004335-ncpawpx4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-haze-660
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ncpawpx4
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x151d526f7a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3444
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.34444
wandb: 
wandb: üöÄ View run misty-haze-660 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/ncpawpx4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_004335-ncpawpx4/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_004450-f9a5mjqm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-morning-661
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/f9a5mjqm
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14dde8f5fa30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run pious-morning-661 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/f9a5mjqm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_004450-f9a5mjqm/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_004603-rgcyl9em
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-dawn-662
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/rgcyl9em
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.7, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14dd20418a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.1222
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.12222
wandb: 
wandb: üöÄ View run expert-dawn-662 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/rgcyl9em
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_004603-rgcyl9em/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_004721-js5pei6f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-frost-663
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/js5pei6f
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14e7890f4d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run twilight-frost-663 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/js5pei6f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_004721-js5pei6f/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_004837-0l8q9pyj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-plasma-664
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/0l8q9pyj
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14a15ef55d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3444
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.385 MB uploadedwandb: - 0.378 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.34444
wandb: 
wandb: üöÄ View run dashing-plasma-664 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/0l8q9pyj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_004837-0l8q9pyj/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_004945-szhm38k2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-flower-665
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/szhm38k2
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14d58e153a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run expert-flower-665 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/szhm38k2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_004945-szhm38k2/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_005100-7xbd7irw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-grass-666
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7xbd7irw
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.3, alpha2=0.9, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x149931bcda30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.1222
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.383 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.12222
wandb: 
wandb: üöÄ View run vital-grass-666 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/7xbd7irw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_005100-7xbd7irw/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_005216-zs1dw9ge
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-waterfall-667
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/zs1dw9ge
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x152a88b019d0>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.381 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run apricot-waterfall-667 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/zs1dw9ge
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_005216-zs1dw9ge/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_005329-wdf7h4uu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sunset-668
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wdf7h4uu
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14b10bed2d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3444
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.34444
wandb: 
wandb: üöÄ View run volcanic-sunset-668 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/wdf7h4uu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_005329-wdf7h4uu/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_005446-as40oike
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sunset-669
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/as40oike
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1470764a1a00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.383 MB uploadedwandb: - 0.387 MB of 0.389 MB uploadedwandb: \ 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run royal-sunset-669 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/as40oike
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_005446-as40oike/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_005602-hb51kwo0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-plasma-670
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hb51kwo0
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.1, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x147026e1dd00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.1222
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.378 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.12222
wandb: 
wandb: üöÄ View run volcanic-plasma-670 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/hb51kwo0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_005602-hb51kwo0/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_005717-mh83lxed
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-durian-671
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/mh83lxed
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-06, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x151791ec1d00>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.381 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run dry-durian-671 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/mh83lxed
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_005717-mh83lxed/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_005836-bpo0sqhw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-gorge-672
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/bpo0sqhw
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=1e-05, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x147c28ed6a90>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3444
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.385 MB uploadedwandb: / 0.387 MB of 0.389 MB uploadedwandb: - 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.34444
wandb: 
wandb: üöÄ View run crimson-gorge-672 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/bpo0sqhw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_005836-bpo0sqhw/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_005952-rasx3tuy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-brook-673
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/rasx3tuy
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.0001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x14bcfca03a30>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.3630
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.385 MB uploadedwandb: \ 0.378 MB of 0.389 MB uploadedwandb: | 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.36296
wandb: 
wandb: üöÄ View run worldly-brook-673 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/rasx3tuy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_005952-rasx3tuy/logs
wandb: Currently logged in as: akshitsinha3. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home2/akshitsinha28/.netrc
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home2/akshitsinha28/AdversarialUnlearning/wandb/run-20240529_010111-po4sve3j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-night-674
wandb: ‚≠êÔ∏è View project at https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: üöÄ View run at https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/po4sve3j
/home2/akshitsinha28/AdversarialUnlearning/grb/utils/utils.py:58: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)
  adj_tensor = torch.sparse.FloatTensor(sparse_concat.t(), sparse_data, torch.Size(adj.shape))
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(self.temp_node),
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
/home2/akshitsinha28/AdversarialUnlearning/unlearn/MEGU.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mat = torch.tensor(mat, dtype=torch.float32)
===========ARGS===========
Namespace(alpha1=0.5, alpha2=0.3, attack='fgsm', damp=0.0, dataset_name='Cora', epsilon_attack=0.3, experiment_name='fgsm_GCN_megu_node', gif_num_runs=2, gif_test_ratio=0.2, hidden_features=[64, 64], iteration=5, kappa=1e-05, lr_attack=0.01, lr_optimizer=0.01, megu_num_epochs=100, megu_num_runs=2, megu_test_ratio=0.2, megu_unlearn_lr=0.001, model='GCN', n_edge_max=64, n_epoch_attack=100, n_epoch_train=200, n_inject_max=32, n_layers=3, poison_model_name='fgsm_GCN', run_sweep=False, scale=50, test_split='easy', unlearn_method='megu', unlearn_request='node', wandb=True)
==========================
===========Dataset==========
<grb.dataset.dataset.Dataset object at 0x1504e2d9ba60>
===========Base Model Loading==========
Test accuracy of model: 0.8185
===========Poisoned Model Loading==========
Test accuracy of model: 0.3630
===========Unlearning==========
Test accuracy of model: 0.1222
=====================
wandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.378 MB uploadedwandb: / 0.378 MB of 0.378 MB uploadedwandb: - 0.378 MB of 0.378 MB uploadedwandb: \ 0.378 MB of 0.378 MB uploadedwandb: | 0.378 MB of 0.389 MB uploadedwandb: / 0.389 MB of 0.389 MB uploadedwandb: 
wandb: Run history:
wandb:      Base Model Test Accuracy ‚ñÅ
wandb:  Poisoned Model Test Accuracy ‚ñÅ
wandb: Unlearned Model Test Accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:      Base Model Test Accuracy 0.81852
wandb:  Poisoned Model Test Accuracy 0.36296
wandb: Unlearned Model Test Accuracy 0.12222
wandb: 
wandb: üöÄ View run sweet-night-674 at: https://wandb.ai/akshitsinha3/corr_graph_unlearn/runs/po4sve3j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/akshitsinha3/corr_graph_unlearn
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240529_010111-po4sve3j/logs
slurmstepd: error: *** JOB 1147437 ON gnode037 CANCELLED AT 2024-05-29T01:02:18 ***
